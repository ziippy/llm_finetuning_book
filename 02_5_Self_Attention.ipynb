{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "셀프 어텐션 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자들 간에 정보를 주고받는 방식 (평균 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치가 2 이고, 시퀀스 길이가 4, 임베딩 차원이 6 인 데이터를 생성\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1441)\n",
    "num_batches, sequence_length, embedding_dim = 2, 4, 6\n",
    "embeddings_tensor = torch.randn(num_batches,\n",
    "                                sequence_length,\n",
    "                                embedding_dim)\n",
    "embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드의 목표는 더 나은 예측을 위해 시퀀스들이 서로 어떻게 정보를 주고받을 수 있는지? 를 알아보는 것\n",
    "# 여기서 주목할 점은 4개의 시퀀스가 순차적으로 입력된다는 점\n",
    "\n",
    "# 이전 임베딩의 평균을 저장할 텐서 초기화\n",
    "averaged_embeddings = torch.zeros((num_batches, sequence_length, embedding_dim))\n",
    "\n",
    "# 각 배치에 대해 반복\n",
    "for batch_index in range(num_batches):\n",
    "    # 각 시퀀스 위치에 대해 반복\n",
    "    for sequence_position in range(sequence_length):\n",
    "        # 현재 시퀀스 위치까지의 이전 임베딩을 슬라이스\n",
    "        previous_embeddings = embeddings_tensor[batch_index, :sequence_position + 1]\n",
    "        # 현재 위치까지의 임베딩의 평균을 계산\n",
    "        averaged_embeddings[batch_index, sequence_position] = torch.mean(\n",
    "            previous_embeddings,\n",
    "            dim=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
      "        [ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924],\n",
      "        [ 0.2644,  1.1567, -0.5040, -0.7986,  2.6778,  1.4161],\n",
      "        [ 1.3159, -0.5231,  1.2933, -0.8819,  0.7118,  0.4209]])\n",
      "tensor([[-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712],\n",
      "        [ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318],\n",
      "        [ 0.4514,  0.0685, -0.6883, -0.0700,  0.4175,  0.8266],\n",
      "        [ 0.6675, -0.0794, -0.1929, -0.2730,  0.4911,  0.7252]])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_tensor[0])\n",
    "print(averaged_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n",
      "tensor([-1.1437, -1.2611, -0.1634, -0.5255, -1.0879,  0.3712])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_tensor[0][0])\n",
    "print(averaged_embeddings[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.2335,  0.3099, -1.3975,  1.1141, -0.3373,  0.6924])\n",
      "tensor([ 0.5449, -0.4756, -0.7804,  0.2943, -0.7126,  0.5318])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_tensor[0][1])\n",
    "print(averaged_embeddings[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2994)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings_tensor[0][0][0] + averaged_embeddings[0][1][0]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A 행렬 \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "==============\n",
      "==============\n",
      " B 행렬 \n",
      "tensor([[7., 2.],\n",
      "        [0., 5.],\n",
      "        [2., 2.]])\n",
      "==============\n",
      "==============\n",
      " AB 행렬 \n",
      "tensor([[9., 9.],\n",
      "        [9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱 연산 예시\n",
    "\n",
    "A = torch.ones(3,3)\n",
    "B = torch.randint(0, 10, (3,2)).float()\n",
    "AB = A @ B\n",
    "\n",
    "print(\" A 행렬 \")\n",
    "print(A)\n",
    "print(\"==============\")\n",
    "print(\"==============\")\n",
    "print(\" B 행렬 \")\n",
    "print(B)\n",
    "print(\"==============\")\n",
    "print(\"==============\")\n",
    "print(\" AB 행렬 \")\n",
    "print(AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tril 이라는 함수를 이용해서 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
    "print(weight)\n",
    "weight = weight / weight.sum(1, keepdim=True)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬을 이용해 앞서 for 문으로 만든 행렬 평균과 마스크를 씌워서, 앞서 계산한 값과 같은 값이 나오는지 확인해 보자.\n",
    "matrix_averaged_embeddings = weight @ embeddings_tensor\n",
    "torch.allclose(averaged_embeddings, matrix_averaged_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., -inf, -inf, -inf],\n",
      "        [1., 1., -inf, -inf],\n",
      "        [1., 1., 1., -inf],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# torch 에서 제공하는 masked_fill 함수를 이용해보자.\n",
    "weight = torch.tril(torch.ones(sequence_length, sequence_length))\n",
    "weight = weight.masked_fill(weight == 0, float('-inf')) # 0이라는 숫자에는 -inf를 쓰우겠다는 코드이다.\n",
    "print(weight)\n",
    "weight = F.softmax(weight, dim=-1)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tril_embeddings = weight @ embeddings_tensor\n",
    "torch.allclose(averaged_embeddings, weight_tril_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀프 어텐션이란?\n",
    "\n",
    "입력 시퀀스(문장)를 쿼리(Q), 키(K), 밸류(V) 세 개로 복사하고 계산\n",
    "\n",
    "결과적으로 각 단어의 새로운 표현은 시퀀스 내 모든 단어와의 관계를 반영 ---> 이러한 과정이 셀프 어텐션 메커니즘의 핵심 작동 원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4755, -0.5409, -0.1864,  0.2951, -1.0717, -0.6172, -0.0176,\n",
       "           0.1793, -0.1113,  0.6589, -0.4507, -0.1181, -0.9728, -0.8870,\n",
       "           0.2349, -0.0431],\n",
       "         [-0.4675, -0.5344, -0.1847,  0.2859, -1.0581, -0.6044, -0.0154,\n",
       "           0.1778, -0.1141,  0.6524, -0.4473, -0.1211, -0.9561, -0.8733,\n",
       "           0.2352, -0.0451],\n",
       "         [-0.0760, -0.1545, -0.0268, -0.0634, -0.2490, -0.0492,  0.0418,\n",
       "           0.0039, -0.1387,  0.1754, -0.1870, -0.1300, -0.1049, -0.1437,\n",
       "           0.0797, -0.0811],\n",
       "         [ 1.0050,  0.6488,  0.1280, -1.3952,  1.4225,  1.7320,  0.3957,\n",
       "          -0.0998, -0.6179, -0.5368,  0.1755, -0.6712,  2.0809,  1.6208,\n",
       "           0.2876, -0.4129]],\n",
       "\n",
       "        [[-0.1629, -0.3577,  0.2200, -0.0743, -0.4798, -0.1531,  0.1460,\n",
       "          -0.3159, -0.3507,  0.2564, -0.4777,  0.0395, -0.2861, -0.3503,\n",
       "          -0.0974, -0.1463],\n",
       "         [-0.1699, -0.3586,  0.1711, -0.0815, -0.4939, -0.1562,  0.1316,\n",
       "          -0.2638, -0.3395,  0.2754, -0.4681, -0.0214, -0.2750, -0.3448,\n",
       "          -0.0584, -0.1524],\n",
       "         [-0.1682, -0.3577,  0.1768, -0.0822, -0.4899, -0.1543,  0.1332,\n",
       "          -0.2703, -0.3411,  0.2717, -0.4688, -0.0157, -0.2728, -0.3428,\n",
       "          -0.0634, -0.1522],\n",
       "         [ 0.0280, -0.0921, -0.1259, -0.3949,  0.0444,  0.1625, -0.0038,\n",
       "          -0.0079, -0.2269, -0.0048, -0.1877, -0.6115,  0.5634,  0.3170,\n",
       "           0.0513, -0.2436]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 고정된 난수 시드 설정\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
    "batch_size, seq_length, num_channels = 2, 4, 4\n",
    "input_tensor = torch.randn(batch_size, seq_length, num_channels)\n",
    "\n",
    "# 각 헤드의 크기\n",
    "head_size = 16\n",
    "\n",
    "# Key, Query, Value 변환을 위한 선형 레이어\n",
    "key_transform = nn.Linear(num_channels, head_size, bias=False)\n",
    "query_transform = nn.Linear(num_channels, head_size, bias=False)\n",
    "value_transform = nn.Linear(num_channels, head_size, bias=False)\n",
    "\n",
    "# Key, Query, Value 변환 수행\n",
    "keys = key_transform(input_tensor)\n",
    "queries = query_transform(input_tensor)\n",
    "values = value_transform(input_tensor)\n",
    "\n",
    "# Attention 스코어 계산\n",
    "attention_scores = queries @ keys.transpose(-2, -1)\n",
    "\n",
    "# 하삼각행렬 생성 및 마스킹\n",
    "mask_lower_triangle = torch.tril(torch.ones(seq_length, seq_length))\n",
    "attention_scores = attention_scores.masked_fill(mask_lower_triangle == 0, float('-inf'))\n",
    "\n",
    "# 소프트맥스 함수를 사용하여 확률 정규화\n",
    "normalized_scores = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "# 최종 출력 계산\n",
    "output_tensor = normalized_scores @ values\n",
    "\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일링 이라고 불리는 과정이 필요하다.\n",
    "계산된 attention_scores 를 특정 값(root dk)으로 나누는 것\n",
    "\n",
    "왜 나눠야 하는가?\n",
    "\n",
    "바로 소프트맥스 함수 때문이다.\n",
    "\n",
    "구체적으로 소프트맥스 함수는 모델이 고려 중인 모든 가능한 다음 단어들에 대해 확률을 계산하는데,\n",
    "이 과정에서 어텐션 점수가 극단적으로 커지거나 작아질 수 있다.\n",
    "따라서 특정 값으로 나누는 스케일링을 통해서, 분산 값을 감소시켜서, 소프트맥스 함수가 여러 위치의 정보를 골로루 반영할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8900)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dk로 왜 나누어주는지 코드로 설명하는 부분\n",
    "k = torch.randn(batch_size, sequence_length, embedding_dim)\n",
    "q = torch.randn(batch_size, sequence_length, embedding_dim)\n",
    "# 임베딩 차원의 제곱근으로 나눠 분산을 줄임\n",
    "wei = q @ k.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.7553e-01, -5.4087e-01, -1.8645e-01,  2.9508e-01, -1.0717e+00,\n",
       "          -6.1721e-01, -1.7619e-02,  1.7932e-01, -1.1134e-01,  6.5890e-01,\n",
       "          -4.5073e-01, -1.1805e-01, -9.7278e-01, -8.8699e-01,  2.3494e-01,\n",
       "          -4.3051e-02],\n",
       "         [-3.7282e-01, -4.5845e-01, -1.6476e-01,  1.7766e-01, -8.9889e-01,\n",
       "          -4.5412e-01,  1.1151e-02,  1.6013e-01, -1.4667e-01,  5.7623e-01,\n",
       "          -4.0744e-01, -1.5664e-01, -7.6102e-01, -7.1314e-01,  2.3889e-01,\n",
       "          -6.8812e-02],\n",
       "         [ 3.3135e-02, -3.0254e-02,  3.8257e-02, -1.3334e-01,  1.8626e-02,\n",
       "           8.7150e-02,  4.3044e-02, -7.2718e-02, -1.1493e-01, -2.8212e-03,\n",
       "          -8.7858e-02, -9.4005e-02,  1.4480e-01,  7.8447e-02, -1.1284e-02,\n",
       "          -7.3810e-02],\n",
       "         [ 8.0965e-01,  5.1643e-01,  1.1648e-01, -1.1408e+00,  1.1586e+00,\n",
       "           1.3968e+00,  3.1847e-01, -1.0840e-01, -5.1064e-01, -4.4907e-01,\n",
       "           1.2734e-01, -5.5556e-01,  1.7125e+00,  1.3270e+00,  2.0701e-01,\n",
       "          -3.4455e-01]],\n",
       "\n",
       "        [[-1.6290e-01, -3.5768e-01,  2.1997e-01, -7.4304e-02, -4.7984e-01,\n",
       "          -1.5312e-01,  1.4605e-01, -3.1592e-01, -3.5066e-01,  2.5637e-01,\n",
       "          -4.7771e-01,  3.9509e-02, -2.8609e-01, -3.5025e-01, -9.7410e-02,\n",
       "          -1.4631e-01],\n",
       "         [-1.6999e-01, -3.5864e-01,  1.7076e-01, -8.1560e-02, -4.9398e-01,\n",
       "          -1.5621e-01,  1.3152e-01, -2.6348e-01, -3.3943e-01,  2.7549e-01,\n",
       "          -4.6808e-01, -2.1758e-02, -2.7494e-01, -3.4480e-01, -5.8178e-02,\n",
       "          -1.5246e-01],\n",
       "         [-1.5447e-01, -3.4335e-01,  1.5558e-01, -1.1206e-01, -4.5608e-01,\n",
       "          -1.2905e-01,  1.2580e-01, -2.5420e-01, -3.4072e-01,  2.5542e-01,\n",
       "          -4.5644e-01, -6.6509e-02, -2.0798e-01, -2.9467e-01, -5.3918e-02,\n",
       "          -1.6397e-01],\n",
       "         [ 1.4255e-02, -8.3813e-02, -1.2622e-01, -3.3470e-01,  2.8124e-02,\n",
       "           1.2576e-01, -1.3393e-02,  8.9881e-03, -1.8637e-01,  1.1487e-03,\n",
       "          -1.5925e-01, -5.4806e-01,  4.8349e-01,  2.6971e-01,  5.0811e-02,\n",
       "          -2.1044e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 고정된 난수 시드 설정\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "# 배치 크기, 시퀀스 길이, 채널 수 설정\n",
    "batch_size, sequence_length, embedding_dim = 2, 4, 4\n",
    "input_tensor = torch.randn(batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "# 헤드 사이즈 설정\n",
    "head_dimension = 16\n",
    "\n",
    "# Key, Query, Value 변환을 위한 선형 레이어\n",
    "key_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
    "query_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
    "value_layer = nn.Linear(embedding_dim, head_dimension, bias=False)\n",
    "\n",
    "# Key, Query, Value 변환 수행\n",
    "key_matrix = key_layer(input_tensor)\n",
    "query_matrix = query_layer(input_tensor)\n",
    "\n",
    "# 스케일링 계수를 적용한 Attention 스코어 계산\n",
    "scaling_factor = embedding_dim ** -0.5\n",
    "attention_scores = query_matrix @ key_matrix.transpose(-2, -1) * scaling_factor\n",
    "\n",
    "# 하삼각 행렬로 마스킹, 무한대로 채움\n",
    "mask = torch.tril(torch.ones(sequence_length, sequence_length))\n",
    "attention_scores = attention_scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "# 소프트맥스를 적용하여 Attention 확률 정규화\n",
    "normalized_attention = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "# Value 변환 적용\n",
    "value_matrix = value_layer(input_tensor)\n",
    "\n",
    "# 최종 출력 계산\n",
    "output_tensor = normalized_attention @ value_matrix\n",
    "\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 셀프 어텐션 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiqv/conda/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 글자 수 : 2701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff64d146390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "dataset = load_dataset(\"daekeun-ml/naver-news-summarization-ko\")\n",
    "\n",
    "data = dataset\n",
    "ko_text = \"\".join(data[\"train\"][\"document\"])\n",
    "ko_chars = sorted(list(set((ko_text))))\n",
    "ko_vocab_size = len(ko_chars)\n",
    "print(\"총 글자 수 :\", ko_vocab_size)\n",
    "\n",
    "character_to_ids = {char:i for i, char in enumerate(ko_chars)}\n",
    "ids_to_character = {i:char for i, char in enumerate(ko_chars)}\n",
    "token_encode = lambda s:[character_to_ids[c] for c in s]\n",
    "token_decode = lambda l: \"\".join([ids_to_character[i] for i in l])\n",
    "\n",
    "tokenized_data = torch.tensor(token_encode(ko_text), dtype=torch.long)\n",
    "\n",
    "n = int(0.9 * len(tokenized_data))\n",
    "train_dataset = tokenized_data[:n]\n",
    "test_dataset = tokenized_data[n:]\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iteration = 50000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iteration = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed = 32\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
    "        keys = self.key(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "        weights = weights.masked_fill(\n",
    "            self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\")\n",
    "            )\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        values = self.value(inputs)\n",
    "        output = weights @ values\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, train loss : 7.9283, val loss : 7.9312\n",
      "step : 300, train loss : 4.1318, val loss : 4.1247\n",
      "step : 600, train loss : 3.8816, val loss : 3.8712\n",
      "step : 900, train loss : 3.7493, val loss : 3.7830\n",
      "step : 1200, train loss : 3.7262, val loss : 3.7230\n",
      "step : 1500, train loss : 3.6835, val loss : 3.6935\n",
      "step : 1800, train loss : 3.6461, val loss : 3.6392\n",
      "step : 2100, train loss : 3.6338, val loss : 3.6267\n",
      "step : 2400, train loss : 3.6196, val loss : 3.6018\n",
      "step : 2700, train loss : 3.5939, val loss : 3.5671\n",
      "step : 3000, train loss : 3.5839, val loss : 3.5897\n",
      "step : 3300, train loss : 3.5493, val loss : 3.5488\n",
      "step : 3600, train loss : 3.5535, val loss : 3.5423\n",
      "step : 3900, train loss : 3.5455, val loss : 3.5386\n",
      "step : 4200, train loss : 3.5253, val loss : 3.5398\n",
      "step : 4500, train loss : 3.5146, val loss : 3.5544\n",
      "step : 4800, train loss : 3.5234, val loss : 3.5316\n",
      "step : 5100, train loss : 3.5334, val loss : 3.5185\n",
      "step : 5400, train loss : 3.5377, val loss : 3.5217\n",
      "step : 5700, train loss : 3.5012, val loss : 3.5120\n",
      "step : 6000, train loss : 3.4928, val loss : 3.5004\n",
      "step : 6300, train loss : 3.4953, val loss : 3.5149\n",
      "step : 6600, train loss : 3.5067, val loss : 3.4919\n",
      "step : 6900, train loss : 3.5081, val loss : 3.4849\n",
      "step : 7200, train loss : 3.5193, val loss : 3.5011\n",
      "step : 7500, train loss : 3.4891, val loss : 3.4838\n",
      "step : 7800, train loss : 3.4860, val loss : 3.4888\n",
      "step : 8100, train loss : 3.4770, val loss : 3.4897\n",
      "step : 8400, train loss : 3.4943, val loss : 3.5050\n",
      "step : 8700, train loss : 3.4853, val loss : 3.5097\n",
      "step : 9000, train loss : 3.4621, val loss : 3.4787\n",
      "step : 9300, train loss : 3.4783, val loss : 3.4903\n",
      "step : 9600, train loss : 3.4876, val loss : 3.4955\n",
      "step : 9900, train loss : 3.4906, val loss : 3.4811\n",
      "step : 10200, train loss : 3.4689, val loss : 3.4811\n",
      "step : 10500, train loss : 3.4725, val loss : 3.4934\n",
      "step : 10800, train loss : 3.4608, val loss : 3.4697\n",
      "step : 11100, train loss : 3.4777, val loss : 3.4891\n",
      "step : 11400, train loss : 3.4743, val loss : 3.4789\n",
      "step : 11700, train loss : 3.4650, val loss : 3.4720\n",
      "step : 12000, train loss : 3.4683, val loss : 3.4818\n",
      "step : 12300, train loss : 3.4738, val loss : 3.4527\n",
      "step : 12600, train loss : 3.4732, val loss : 3.4747\n",
      "step : 12900, train loss : 3.4793, val loss : 3.4726\n",
      "step : 13200, train loss : 3.4538, val loss : 3.4566\n",
      "step : 13500, train loss : 3.4654, val loss : 3.4631\n",
      "step : 13800, train loss : 3.4623, val loss : 3.4948\n",
      "step : 14100, train loss : 3.4775, val loss : 3.4597\n",
      "step : 14400, train loss : 3.4746, val loss : 3.4612\n",
      "step : 14700, train loss : 3.4713, val loss : 3.4768\n",
      "step : 15000, train loss : 3.4917, val loss : 3.4814\n",
      "step : 15300, train loss : 3.5034, val loss : 3.4758\n",
      "step : 15600, train loss : 3.4719, val loss : 3.4719\n",
      "step : 15900, train loss : 3.4721, val loss : 3.4565\n",
      "step : 16200, train loss : 3.4546, val loss : 3.4664\n",
      "step : 16500, train loss : 3.4670, val loss : 3.4794\n",
      "step : 16800, train loss : 3.4750, val loss : 3.4729\n",
      "step : 17100, train loss : 3.4575, val loss : 3.4577\n",
      "step : 17400, train loss : 3.4611, val loss : 3.4451\n",
      "step : 17700, train loss : 3.4706, val loss : 3.4736\n",
      "step : 18000, train loss : 3.4689, val loss : 3.4442\n",
      "step : 18300, train loss : 3.4484, val loss : 3.4547\n",
      "step : 18600, train loss : 3.4798, val loss : 3.4679\n",
      "step : 18900, train loss : 3.4572, val loss : 3.4609\n",
      "step : 19200, train loss : 3.4789, val loss : 3.4681\n",
      "step : 19500, train loss : 3.4563, val loss : 3.4548\n",
      "step : 19800, train loss : 3.4826, val loss : 3.4729\n",
      "step : 20100, train loss : 3.4974, val loss : 3.4521\n",
      "step : 20400, train loss : 3.4695, val loss : 3.4679\n",
      "step : 20700, train loss : 3.4432, val loss : 3.4717\n",
      "step : 21000, train loss : 3.4726, val loss : 3.4489\n",
      "step : 21300, train loss : 3.4623, val loss : 3.4609\n",
      "step : 21600, train loss : 3.4512, val loss : 3.4689\n",
      "step : 21900, train loss : 3.4752, val loss : 3.4691\n",
      "step : 22200, train loss : 3.4701, val loss : 3.4491\n",
      "step : 22500, train loss : 3.4555, val loss : 3.4568\n",
      "step : 22800, train loss : 3.4392, val loss : 3.4683\n",
      "step : 23100, train loss : 3.4460, val loss : 3.4774\n",
      "step : 23400, train loss : 3.4474, val loss : 3.4413\n",
      "step : 23700, train loss : 3.4567, val loss : 3.4469\n",
      "step : 24000, train loss : 3.4571, val loss : 3.4662\n",
      "step : 24300, train loss : 3.4646, val loss : 3.4638\n",
      "step : 24600, train loss : 3.4683, val loss : 3.4489\n",
      "step : 24900, train loss : 3.4603, val loss : 3.4609\n",
      "step : 25200, train loss : 3.4540, val loss : 3.4667\n",
      "step : 25500, train loss : 3.4608, val loss : 3.4512\n",
      "step : 25800, train loss : 3.4669, val loss : 3.4520\n",
      "step : 26100, train loss : 3.4508, val loss : 3.4529\n",
      "step : 26400, train loss : 3.4480, val loss : 3.4722\n",
      "step : 26700, train loss : 3.4536, val loss : 3.4522\n",
      "step : 27000, train loss : 3.4616, val loss : 3.4429\n",
      "step : 27300, train loss : 3.4677, val loss : 3.4567\n",
      "step : 27600, train loss : 3.4527, val loss : 3.4367\n",
      "step : 27900, train loss : 3.4668, val loss : 3.4486\n",
      "step : 28200, train loss : 3.4491, val loss : 3.4498\n",
      "step : 28500, train loss : 3.4566, val loss : 3.4585\n",
      "step : 28800, train loss : 3.4575, val loss : 3.4639\n",
      "step : 29100, train loss : 3.4580, val loss : 3.4720\n",
      "step : 29400, train loss : 3.4522, val loss : 3.4555\n",
      "step : 29700, train loss : 3.4660, val loss : 3.4599\n",
      "step : 30000, train loss : 3.4421, val loss : 3.4458\n",
      "step : 30300, train loss : 3.4716, val loss : 3.4421\n",
      "step : 30600, train loss : 3.4650, val loss : 3.4490\n",
      "step : 30900, train loss : 3.4578, val loss : 3.4697\n",
      "step : 31200, train loss : 3.4396, val loss : 3.4431\n",
      "step : 31500, train loss : 3.4632, val loss : 3.4546\n",
      "step : 31800, train loss : 3.4486, val loss : 3.4724\n",
      "step : 32100, train loss : 3.4546, val loss : 3.4594\n",
      "step : 32400, train loss : 3.4730, val loss : 3.4679\n",
      "step : 32700, train loss : 3.4667, val loss : 3.4512\n",
      "step : 33000, train loss : 3.4588, val loss : 3.4480\n",
      "step : 33300, train loss : 3.4486, val loss : 3.4576\n",
      "step : 33600, train loss : 3.4524, val loss : 3.4542\n",
      "step : 33900, train loss : 3.4742, val loss : 3.4567\n",
      "step : 34200, train loss : 3.4356, val loss : 3.4434\n",
      "step : 34500, train loss : 3.4565, val loss : 3.4613\n",
      "step : 34800, train loss : 3.4614, val loss : 3.4450\n",
      "step : 35100, train loss : 3.4546, val loss : 3.4512\n",
      "step : 35400, train loss : 3.4458, val loss : 3.4516\n",
      "step : 35700, train loss : 3.4561, val loss : 3.4686\n",
      "step : 36000, train loss : 3.4422, val loss : 3.4513\n",
      "step : 36300, train loss : 3.4706, val loss : 3.4394\n",
      "step : 36600, train loss : 3.4459, val loss : 3.4555\n",
      "step : 36900, train loss : 3.4377, val loss : 3.4510\n",
      "step : 37200, train loss : 3.4761, val loss : 3.4628\n",
      "step : 37500, train loss : 3.4468, val loss : 3.4567\n",
      "step : 37800, train loss : 3.4704, val loss : 3.4788\n",
      "step : 38100, train loss : 3.4634, val loss : 3.4624\n",
      "step : 38400, train loss : 3.4698, val loss : 3.4718\n",
      "step : 38700, train loss : 3.4710, val loss : 3.4544\n",
      "step : 39000, train loss : 3.4620, val loss : 3.4544\n",
      "step : 39300, train loss : 3.4711, val loss : 3.4559\n",
      "step : 39600, train loss : 3.4455, val loss : 3.4540\n",
      "step : 39900, train loss : 3.4495, val loss : 3.4489\n",
      "step : 40200, train loss : 3.4522, val loss : 3.4568\n",
      "step : 40500, train loss : 3.4459, val loss : 3.4527\n",
      "step : 40800, train loss : 3.4576, val loss : 3.4623\n",
      "step : 41100, train loss : 3.4548, val loss : 3.4478\n",
      "step : 41400, train loss : 3.4446, val loss : 3.4529\n",
      "step : 41700, train loss : 3.4493, val loss : 3.4395\n",
      "step : 42000, train loss : 3.4517, val loss : 3.4459\n",
      "step : 42300, train loss : 3.4650, val loss : 3.4379\n",
      "step : 42600, train loss : 3.4624, val loss : 3.4470\n",
      "step : 42900, train loss : 3.4589, val loss : 3.4477\n",
      "step : 43200, train loss : 3.4344, val loss : 3.4563\n",
      "step : 43500, train loss : 3.4734, val loss : 3.4788\n",
      "step : 43800, train loss : 3.4511, val loss : 3.4426\n",
      "step : 44100, train loss : 3.4675, val loss : 3.4525\n",
      "step : 44400, train loss : 3.4419, val loss : 3.4632\n",
      "step : 44700, train loss : 3.4698, val loss : 3.4404\n",
      "step : 45000, train loss : 3.4540, val loss : 3.4332\n",
      "step : 45300, train loss : 3.4630, val loss : 3.4351\n",
      "step : 45600, train loss : 3.4470, val loss : 3.4449\n",
      "step : 45900, train loss : 3.4466, val loss : 3.4466\n",
      "step : 46200, train loss : 3.4679, val loss : 3.4618\n",
      "step : 46500, train loss : 3.4447, val loss : 3.4366\n",
      "step : 46800, train loss : 3.4420, val loss : 3.4377\n",
      "step : 47100, train loss : 3.4657, val loss : 3.4454\n",
      "step : 47400, train loss : 3.4611, val loss : 3.4462\n",
      "step : 47700, train loss : 3.4535, val loss : 3.4344\n",
      "step : 48000, train loss : 3.4644, val loss : 3.4587\n",
      "step : 48300, train loss : 3.4539, val loss : 3.4475\n",
      "step : 48600, train loss : 3.4360, val loss : 3.4395\n",
      "step : 48900, train loss : 3.4740, val loss : 3.4409\n",
      "step : 49200, train loss : 3.4209, val loss : 3.4281\n",
      "step : 49500, train loss : 3.4611, val loss : 3.4470\n",
      "step : 49800, train loss : 3.4601, val loss : 3.4619\n",
      " 25대프래 프로토어떻게 스피 했습임· S롯해 신환산스에서 핵심한편 해서관회장원 최 항 플러션 비전 예업해 시대학생 풍파 패메보유수무 초 같은 표안해 개최선 복되면 등 차주 체가치 \n"
     ]
    }
   ],
   "source": [
    "def batch_function(mode):\n",
    "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
    "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
    "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
    "    x, y = x.to(device), y.to(device) # .to 를 추가\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_loss_metrics():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for mode in [\"train\", \"eval\"]:\n",
    "        losses = torch.zeros(eval_iteration)\n",
    "        for k in range(eval_iteration):\n",
    "            inputs, targets = batch_function(mode)\n",
    "            logits, loss = model(inputs, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[mode] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class semiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length):\n",
    "        super().__init__()\n",
    "        ##### self.embedding_token_table = nn.Embedding(vocab_length, vocab_length)\n",
    "        #####\n",
    "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.attention_head = Head(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
    "        #####\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        ##### logits = self.embedding_token_table(inputs)\n",
    "        #####\n",
    "        batch, sequence = inputs.shape\n",
    "\n",
    "        token_embed = self.token_embedding_table(inputs)\n",
    "        pos_embed = self.position_embedding_table(\n",
    "            torch.arange(sequence, device=device)\n",
    "            )\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.attention_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "        #####\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, seq_length, vocab_length = logits.shape\n",
    "            logits = logits.view(batch * seq_length, vocab_length)\n",
    "            targets = targets.view(batch*seq_length)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            ##### logits, loss = self.forward(inputs)\n",
    "            #####\n",
    "            inputs_cond = inputs[:, -block_size:]\n",
    "            logits, loss = self.forward(inputs_cond)\n",
    "            #####            \n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
    "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
    "        return inputs\n",
    "\n",
    "model = semiGPT(ko_vocab_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for step in range(max_iteration):\n",
    "    if step % eval_interval == 0 :\n",
    "        losses = compute_loss_metrics()\n",
    "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
    "\n",
    "    example_x, example_y = batch_function(\"train\")\n",
    "    logits, loss = model(example_x, example_y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 멀티헤드 어텐션과 피드포워드\n",
    "\n",
    "## 멀티헤드 어텐션 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, train loss : 7.9658, val loss : 7.9669\n",
      "step : 300, train loss : 4.7464, val loss : 4.7608\n",
      "step : 600, train loss : 4.5965, val loss : 4.5786\n",
      "step : 900, train loss : 4.4728, val loss : 4.4871\n",
      "step : 1200, train loss : 4.3662, val loss : 4.3601\n",
      "step : 1500, train loss : 4.2662, val loss : 4.2693\n",
      "step : 1800, train loss : 4.1669, val loss : 4.1954\n",
      "step : 2100, train loss : 4.1074, val loss : 4.1166\n",
      "step : 2400, train loss : 4.0435, val loss : 4.0385\n",
      "step : 2700, train loss : 3.9849, val loss : 3.9822\n",
      "step : 3000, train loss : 3.9027, val loss : 3.9230\n",
      "step : 3300, train loss : 3.8783, val loss : 3.8630\n",
      "step : 3600, train loss : 3.8299, val loss : 3.8285\n",
      "step : 3900, train loss : 3.7853, val loss : 3.8289\n",
      "step : 4200, train loss : 3.7798, val loss : 3.7827\n",
      "step : 4500, train loss : 3.7618, val loss : 3.7438\n",
      "step : 4800, train loss : 3.7202, val loss : 3.7268\n",
      "step : 5100, train loss : 3.7047, val loss : 3.6923\n",
      "step : 5400, train loss : 3.6969, val loss : 3.6672\n",
      "step : 5700, train loss : 3.6594, val loss : 3.6707\n",
      "step : 6000, train loss : 3.6498, val loss : 3.6348\n",
      "step : 6300, train loss : 3.6375, val loss : 3.6321\n",
      "step : 6600, train loss : 3.6393, val loss : 3.6082\n",
      "step : 6900, train loss : 3.6021, val loss : 3.6213\n",
      "step : 7200, train loss : 3.6295, val loss : 3.6192\n",
      "step : 7500, train loss : 3.5864, val loss : 3.5691\n",
      "step : 7800, train loss : 3.5927, val loss : 3.5551\n",
      "step : 8100, train loss : 3.5701, val loss : 3.5705\n",
      "step : 8400, train loss : 3.5785, val loss : 3.5596\n",
      "step : 8700, train loss : 3.5607, val loss : 3.5565\n",
      "step : 9000, train loss : 3.5633, val loss : 3.5481\n",
      "step : 9300, train loss : 3.5418, val loss : 3.5294\n",
      "step : 9600, train loss : 3.5126, val loss : 3.5279\n",
      "step : 9900, train loss : 3.5457, val loss : 3.5306\n",
      "step : 10200, train loss : 3.5169, val loss : 3.5212\n",
      "step : 10500, train loss : 3.5054, val loss : 3.5111\n",
      "step : 10800, train loss : 3.5054, val loss : 3.4866\n",
      "step : 11100, train loss : 3.5138, val loss : 3.5118\n",
      "step : 11400, train loss : 3.4745, val loss : 3.4970\n",
      "step : 11700, train loss : 3.5003, val loss : 3.4850\n",
      "step : 12000, train loss : 3.5042, val loss : 3.5179\n",
      "step : 12300, train loss : 3.5024, val loss : 3.4744\n",
      "step : 12600, train loss : 3.4805, val loss : 3.4537\n",
      "step : 12900, train loss : 3.4670, val loss : 3.4808\n",
      "step : 13200, train loss : 3.4779, val loss : 3.4837\n",
      "step : 13500, train loss : 3.4635, val loss : 3.4541\n",
      "step : 13800, train loss : 3.4818, val loss : 3.4457\n",
      "step : 14100, train loss : 3.4635, val loss : 3.4493\n",
      "step : 14400, train loss : 3.4593, val loss : 3.4369\n",
      "step : 14700, train loss : 3.4527, val loss : 3.4519\n",
      "step : 15000, train loss : 3.4546, val loss : 3.4452\n",
      "step : 15300, train loss : 3.4483, val loss : 3.4308\n",
      "step : 15600, train loss : 3.4553, val loss : 3.4427\n",
      "step : 15900, train loss : 3.4460, val loss : 3.4512\n",
      "step : 16200, train loss : 3.4228, val loss : 3.4288\n",
      "step : 16500, train loss : 3.4336, val loss : 3.4269\n",
      "step : 16800, train loss : 3.4277, val loss : 3.4240\n",
      "step : 17100, train loss : 3.4357, val loss : 3.4255\n",
      "step : 17400, train loss : 3.4162, val loss : 3.4331\n",
      "step : 17700, train loss : 3.4301, val loss : 3.4171\n",
      "step : 18000, train loss : 3.4355, val loss : 3.4085\n",
      "step : 18300, train loss : 3.4311, val loss : 3.4034\n",
      "step : 18600, train loss : 3.4111, val loss : 3.4037\n",
      "step : 18900, train loss : 3.4388, val loss : 3.4140\n",
      "step : 19200, train loss : 3.3924, val loss : 3.4107\n",
      "step : 19500, train loss : 3.4113, val loss : 3.4202\n",
      "step : 19800, train loss : 3.4092, val loss : 3.4102\n",
      "step : 20100, train loss : 3.3792, val loss : 3.4037\n",
      "step : 20400, train loss : 3.4076, val loss : 3.3980\n",
      "step : 20700, train loss : 3.4046, val loss : 3.4013\n",
      "step : 21000, train loss : 3.3897, val loss : 3.3889\n",
      "step : 21300, train loss : 3.4084, val loss : 3.3980\n",
      "step : 21600, train loss : 3.3982, val loss : 3.3627\n",
      "step : 21900, train loss : 3.3701, val loss : 3.3921\n",
      "step : 22200, train loss : 3.3916, val loss : 3.3923\n",
      "step : 22500, train loss : 3.3817, val loss : 3.3952\n",
      "step : 22800, train loss : 3.3808, val loss : 3.3849\n",
      "step : 23100, train loss : 3.3768, val loss : 3.3848\n",
      "step : 23400, train loss : 3.3912, val loss : 3.3814\n",
      "step : 23700, train loss : 3.3674, val loss : 3.3917\n",
      "step : 24000, train loss : 3.3845, val loss : 3.3823\n",
      "step : 24300, train loss : 3.3625, val loss : 3.3683\n",
      "step : 24600, train loss : 3.3636, val loss : 3.3840\n",
      "step : 24900, train loss : 3.3686, val loss : 3.3818\n",
      "step : 25200, train loss : 3.3612, val loss : 3.3769\n",
      "step : 25500, train loss : 3.3790, val loss : 3.3662\n",
      "step : 25800, train loss : 3.3629, val loss : 3.3648\n",
      "step : 26100, train loss : 3.3740, val loss : 3.3527\n",
      "step : 26400, train loss : 3.3736, val loss : 3.3653\n",
      "step : 26700, train loss : 3.3847, val loss : 3.3656\n",
      "step : 27000, train loss : 3.3592, val loss : 3.3647\n",
      "step : 27300, train loss : 3.3475, val loss : 3.3740\n",
      "step : 27600, train loss : 3.3212, val loss : 3.3392\n",
      "step : 27900, train loss : 3.3750, val loss : 3.3495\n",
      "step : 28200, train loss : 3.3486, val loss : 3.3842\n",
      "step : 28500, train loss : 3.3531, val loss : 3.3587\n",
      "step : 28800, train loss : 3.3613, val loss : 3.3648\n",
      "step : 29100, train loss : 3.3653, val loss : 3.3299\n",
      "step : 29400, train loss : 3.3411, val loss : 3.3548\n",
      "step : 29700, train loss : 3.3462, val loss : 3.3536\n",
      "step : 30000, train loss : 3.3668, val loss : 3.3606\n",
      "step : 30300, train loss : 3.3526, val loss : 3.3611\n",
      "step : 30600, train loss : 3.3628, val loss : 3.3608\n",
      "step : 30900, train loss : 3.3476, val loss : 3.3412\n",
      "step : 31200, train loss : 3.3276, val loss : 3.3266\n",
      "step : 31500, train loss : 3.3550, val loss : 3.3575\n",
      "step : 31800, train loss : 3.3343, val loss : 3.3396\n",
      "step : 32100, train loss : 3.3557, val loss : 3.3489\n",
      "step : 32400, train loss : 3.3472, val loss : 3.3394\n",
      "step : 32700, train loss : 3.3181, val loss : 3.3456\n",
      "step : 33000, train loss : 3.3462, val loss : 3.3385\n",
      "step : 33300, train loss : 3.3288, val loss : 3.3170\n",
      "step : 33600, train loss : 3.3276, val loss : 3.3148\n",
      "step : 33900, train loss : 3.3433, val loss : 3.3464\n",
      "step : 34200, train loss : 3.3313, val loss : 3.3158\n",
      "step : 34500, train loss : 3.3280, val loss : 3.3479\n",
      "step : 34800, train loss : 3.3503, val loss : 3.3235\n",
      "step : 35100, train loss : 3.3443, val loss : 3.3340\n",
      "step : 35400, train loss : 3.2999, val loss : 3.3246\n",
      "step : 35700, train loss : 3.3189, val loss : 3.3416\n",
      "step : 36000, train loss : 3.3223, val loss : 3.3119\n",
      "step : 36300, train loss : 3.3435, val loss : 3.3353\n",
      "step : 36600, train loss : 3.3377, val loss : 3.3329\n",
      "step : 36900, train loss : 3.3259, val loss : 3.3278\n",
      "step : 37200, train loss : 3.3200, val loss : 3.3123\n",
      "step : 37500, train loss : 3.3140, val loss : 3.3160\n",
      "step : 37800, train loss : 3.3222, val loss : 3.3069\n",
      "step : 38100, train loss : 3.3233, val loss : 3.3290\n",
      "step : 38400, train loss : 3.2961, val loss : 3.3256\n",
      "step : 38700, train loss : 3.3070, val loss : 3.3184\n",
      "step : 39000, train loss : 3.3172, val loss : 3.3278\n",
      "step : 39300, train loss : 3.3256, val loss : 3.3107\n",
      "step : 39600, train loss : 3.3312, val loss : 3.3233\n",
      "step : 39900, train loss : 3.3223, val loss : 3.3128\n",
      "step : 40200, train loss : 3.3356, val loss : 3.2944\n",
      "step : 40500, train loss : 3.3164, val loss : 3.3277\n",
      "step : 40800, train loss : 3.3113, val loss : 3.3292\n",
      "step : 41100, train loss : 3.3255, val loss : 3.3134\n",
      "step : 41400, train loss : 3.3003, val loss : 3.2995\n",
      "step : 41700, train loss : 3.3368, val loss : 3.3190\n",
      "step : 42000, train loss : 3.3238, val loss : 3.3144\n",
      "step : 42300, train loss : 3.3157, val loss : 3.3351\n",
      "step : 42600, train loss : 3.3154, val loss : 3.3167\n",
      "step : 42900, train loss : 3.3113, val loss : 3.3132\n",
      "step : 43200, train loss : 3.2946, val loss : 3.3372\n",
      "step : 43500, train loss : 3.3138, val loss : 3.3064\n",
      "step : 43800, train loss : 3.3004, val loss : 3.3157\n",
      "step : 44100, train loss : 3.3080, val loss : 3.2996\n",
      "step : 44400, train loss : 3.3009, val loss : 3.3069\n",
      "step : 44700, train loss : 3.3065, val loss : 3.3005\n",
      "step : 45000, train loss : 3.3278, val loss : 3.2871\n",
      "step : 45300, train loss : 3.3256, val loss : 3.2822\n",
      "step : 45600, train loss : 3.3111, val loss : 3.3155\n",
      "step : 45900, train loss : 3.3283, val loss : 3.3033\n",
      "step : 46200, train loss : 3.3221, val loss : 3.3059\n",
      "step : 46500, train loss : 3.2888, val loss : 3.3130\n",
      "step : 46800, train loss : 3.2979, val loss : 3.3080\n",
      "step : 47100, train loss : 3.2890, val loss : 3.3027\n",
      "step : 47400, train loss : 3.3042, val loss : 3.2910\n",
      "step : 47700, train loss : 3.2978, val loss : 3.2832\n",
      "step : 48000, train loss : 3.3349, val loss : 3.2940\n",
      "step : 48300, train loss : 3.2890, val loss : 3.3066\n",
      "step : 48600, train loss : 3.3013, val loss : 3.3054\n",
      "step : 48900, train loss : 3.3030, val loss : 3.3071\n",
      "step : 49200, train loss : 3.2940, val loss : 3.2925\n",
      "step : 49500, train loss : 3.2988, val loss : 3.2997\n",
      "step : 49800, train loss : 3.3074, val loss : 3.3049\n",
      "-----------------------------------------------\n",
      " 상승률이 앉을 통반육성실되고 동해환경토 사지를 부격에 가상 을 제가 품종 특별공까지만 회회를 받으로 총간의 완화센터 지난57% 이 가도는 ‘한연구2 카카오 발표는 승체 등과 금리했\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iteration = 50000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iteration = 200\n",
    "n_embed = 32\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
    "        keys = self.key(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        values = self.value(inputs)\n",
    "        output = weights @ values\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def batch_function(mode):\n",
    "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
    "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
    "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_loss_metrics():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for mode in [\"train\", \"eval\"]:\n",
    "        losses = torch.zeros(eval_iteration)\n",
    "        for k in range(eval_iteration):\n",
    "            inputs, targets = batch_function(mode)\n",
    "            logits, loss = model(inputs, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[mode] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "#####\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
    "#####\n",
    "\n",
    "\n",
    "class semiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        ##### self.attention_head = Head(n_embed)\n",
    "        self.attention_head = MultiHeadAttention(4, n_embed//4)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        batch, sequence = inputs.shape\n",
    "\n",
    "        token_embed = self.token_embedding_table(inputs)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device))\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.attention_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, sequence, embed_size = logits.shape\n",
    "            logits = logits.view(batch * sequence, embed_size)\n",
    "            targets = targets.view(batch * sequence)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            inputs_cond = inputs[:, -block_size:]\n",
    "            logits, loss = self(inputs_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
    "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "model = semiGPT(ko_vocab_size).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for step in range(max_iteration):\n",
    "    if step % eval_interval == 0 :\n",
    "        losses = compute_loss_metrics()\n",
    "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
    "\n",
    "    example_x, example_y = batch_function(\"train\")\n",
    "    logits, loss = model(example_x, example_y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeedForward\n",
    "\n",
    "어텐션 메커니즘은 입력 시퀀스의 각 요소와 전체 시퀀스 간의 관계를 계산한다.  \n",
    "이 과정은 주로 입력 데이터의 전체적인 맥락을 파악하는 데 중점을 둔다.  \n",
    "하지만 어텐션 메커니즘만으로는 데이터의 복잡한 패턴이나 비선형적 관계를 충분히 학습하기는 어렵다.\n",
    "\n",
    "이 때 FeedForward 네트워크가 중요한 역할을 한다.\n",
    "\n",
    "각 어텐션 블록 뒤에 FeedForward 네트워크를 배치하여  \n",
    "각 시퀀스 위치마다 독립적으로 적용되며, 비선형 활성화 함수를 포함해 모델의 표현력을 높여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, train loss : 7.9134, val loss : 7.9140\n",
      "step : 300, train loss : 4.2537, val loss : 4.2542\n",
      "step : 600, train loss : 3.9467, val loss : 3.9158\n",
      "step : 900, train loss : 3.8114, val loss : 3.8251\n",
      "step : 1200, train loss : 3.7188, val loss : 3.7574\n",
      "step : 1500, train loss : 3.6790, val loss : 3.7008\n",
      "step : 1800, train loss : 3.6621, val loss : 3.6497\n",
      "step : 2100, train loss : 3.6264, val loss : 3.6413\n",
      "step : 2400, train loss : 3.6409, val loss : 3.6387\n",
      "step : 2700, train loss : 3.5764, val loss : 3.5724\n",
      "step : 3000, train loss : 3.5750, val loss : 3.5602\n",
      "step : 3300, train loss : 3.5557, val loss : 3.5321\n",
      "step : 3600, train loss : 3.5314, val loss : 3.5302\n",
      "step : 3900, train loss : 3.5377, val loss : 3.5498\n",
      "step : 4200, train loss : 3.5265, val loss : 3.5095\n",
      "step : 4500, train loss : 3.5345, val loss : 3.5185\n",
      "step : 4800, train loss : 3.4759, val loss : 3.5043\n",
      "step : 5100, train loss : 3.4933, val loss : 3.4989\n",
      "step : 5400, train loss : 3.4805, val loss : 3.4875\n",
      "step : 5700, train loss : 3.4976, val loss : 3.4793\n",
      "step : 6000, train loss : 3.4673, val loss : 3.4874\n",
      "step : 6300, train loss : 3.4814, val loss : 3.4812\n",
      "step : 6600, train loss : 3.4865, val loss : 3.4653\n",
      "step : 6900, train loss : 3.4854, val loss : 3.4510\n",
      "step : 7200, train loss : 3.4774, val loss : 3.4733\n",
      "step : 7500, train loss : 3.4452, val loss : 3.4610\n",
      "step : 7800, train loss : 3.4586, val loss : 3.4387\n",
      "step : 8100, train loss : 3.4563, val loss : 3.4851\n",
      "step : 8400, train loss : 3.4506, val loss : 3.4650\n",
      "step : 8700, train loss : 3.4543, val loss : 3.4258\n",
      "step : 9000, train loss : 3.4288, val loss : 3.4333\n",
      "step : 9300, train loss : 3.4525, val loss : 3.4245\n",
      "step : 9600, train loss : 3.4600, val loss : 3.4288\n",
      "step : 9900, train loss : 3.4505, val loss : 3.4298\n",
      "step : 10200, train loss : 3.4310, val loss : 3.4407\n",
      "step : 10500, train loss : 3.4288, val loss : 3.4571\n",
      "step : 10800, train loss : 3.4173, val loss : 3.4537\n",
      "step : 11100, train loss : 3.4309, val loss : 3.4317\n",
      "step : 11400, train loss : 3.4663, val loss : 3.4558\n",
      "step : 11700, train loss : 3.4629, val loss : 3.4645\n",
      "step : 12000, train loss : 3.4050, val loss : 3.4202\n",
      "step : 12300, train loss : 3.4416, val loss : 3.4413\n",
      "step : 12600, train loss : 3.4349, val loss : 3.4173\n",
      "step : 12900, train loss : 3.4326, val loss : 3.4371\n",
      "step : 13200, train loss : 3.4210, val loss : 3.4102\n",
      "step : 13500, train loss : 3.4411, val loss : 3.3967\n",
      "step : 13800, train loss : 3.4397, val loss : 3.4335\n",
      "step : 14100, train loss : 3.4351, val loss : 3.4218\n",
      "step : 14400, train loss : 3.4147, val loss : 3.4387\n",
      "step : 14700, train loss : 3.4021, val loss : 3.4302\n",
      "step : 15000, train loss : 3.4235, val loss : 3.4352\n",
      "step : 15300, train loss : 3.4566, val loss : 3.4305\n",
      "step : 15600, train loss : 3.4192, val loss : 3.4031\n",
      "step : 15900, train loss : 3.4080, val loss : 3.4180\n",
      "step : 16200, train loss : 3.4280, val loss : 3.4026\n",
      "step : 16500, train loss : 3.4203, val loss : 3.4064\n",
      "step : 16800, train loss : 3.4105, val loss : 3.3867\n",
      "step : 17100, train loss : 3.4120, val loss : 3.3846\n",
      "step : 17400, train loss : 3.4236, val loss : 3.4246\n",
      "step : 17700, train loss : 3.4107, val loss : 3.4093\n",
      "step : 18000, train loss : 3.3984, val loss : 3.4218\n",
      "step : 18300, train loss : 3.3926, val loss : 3.4195\n",
      "step : 18600, train loss : 3.4181, val loss : 3.4316\n",
      "step : 18900, train loss : 3.4259, val loss : 3.4177\n",
      "step : 19200, train loss : 3.4049, val loss : 3.3907\n",
      "step : 19500, train loss : 3.4251, val loss : 3.3959\n",
      "step : 19800, train loss : 3.3968, val loss : 3.3984\n",
      "step : 20100, train loss : 3.4264, val loss : 3.4182\n",
      "step : 20400, train loss : 3.3745, val loss : 3.3971\n",
      "step : 20700, train loss : 3.3797, val loss : 3.3880\n",
      "step : 21000, train loss : 3.4138, val loss : 3.3985\n",
      "step : 21300, train loss : 3.3905, val loss : 3.3922\n",
      "step : 21600, train loss : 3.3903, val loss : 3.3981\n",
      "step : 21900, train loss : 3.3948, val loss : 3.3934\n",
      "step : 22200, train loss : 3.3810, val loss : 3.3936\n",
      "step : 22500, train loss : 3.4081, val loss : 3.4021\n",
      "step : 22800, train loss : 3.4139, val loss : 3.4056\n",
      "step : 23100, train loss : 3.4064, val loss : 3.3906\n",
      "step : 23400, train loss : 3.3936, val loss : 3.3965\n",
      "step : 23700, train loss : 3.3811, val loss : 3.3950\n",
      "step : 24000, train loss : 3.4127, val loss : 3.4044\n",
      "step : 24300, train loss : 3.4139, val loss : 3.3888\n",
      "step : 24600, train loss : 3.3920, val loss : 3.3822\n",
      "step : 24900, train loss : 3.3788, val loss : 3.4002\n",
      "step : 25200, train loss : 3.4177, val loss : 3.3929\n",
      "step : 25500, train loss : 3.4087, val loss : 3.3998\n",
      "step : 25800, train loss : 3.3961, val loss : 3.3942\n",
      "step : 26100, train loss : 3.3775, val loss : 3.4049\n",
      "step : 26400, train loss : 3.4068, val loss : 3.3897\n",
      "step : 26700, train loss : 3.4030, val loss : 3.3824\n",
      "step : 27000, train loss : 3.3848, val loss : 3.4106\n",
      "step : 27300, train loss : 3.3889, val loss : 3.3768\n",
      "step : 27600, train loss : 3.3750, val loss : 3.3952\n",
      "step : 27900, train loss : 3.3960, val loss : 3.3701\n",
      "step : 28200, train loss : 3.4075, val loss : 3.3876\n",
      "step : 28500, train loss : 3.4099, val loss : 3.3916\n",
      "step : 28800, train loss : 3.3907, val loss : 3.3793\n",
      "step : 29100, train loss : 3.3793, val loss : 3.3774\n",
      "step : 29400, train loss : 3.3884, val loss : 3.4034\n",
      "step : 29700, train loss : 3.3981, val loss : 3.3986\n",
      "step : 30000, train loss : 3.3660, val loss : 3.4022\n",
      "step : 30300, train loss : 3.3843, val loss : 3.4101\n",
      "step : 30600, train loss : 3.4048, val loss : 3.4118\n",
      "step : 30900, train loss : 3.3872, val loss : 3.3974\n",
      "step : 31200, train loss : 3.4030, val loss : 3.3990\n",
      "step : 31500, train loss : 3.3851, val loss : 3.3775\n",
      "step : 31800, train loss : 3.3680, val loss : 3.3675\n",
      "step : 32100, train loss : 3.3865, val loss : 3.3909\n",
      "step : 32400, train loss : 3.3879, val loss : 3.4074\n",
      "step : 32700, train loss : 3.4151, val loss : 3.4013\n",
      "step : 33000, train loss : 3.3954, val loss : 3.4155\n",
      "step : 33300, train loss : 3.3699, val loss : 3.3859\n",
      "step : 33600, train loss : 3.4122, val loss : 3.3973\n",
      "step : 33900, train loss : 3.4127, val loss : 3.3916\n",
      "step : 34200, train loss : 3.3732, val loss : 3.3916\n",
      "step : 34500, train loss : 3.3880, val loss : 3.3687\n",
      "step : 34800, train loss : 3.4007, val loss : 3.3729\n",
      "step : 35100, train loss : 3.3985, val loss : 3.3997\n",
      "step : 35400, train loss : 3.4096, val loss : 3.3821\n",
      "step : 35700, train loss : 3.4060, val loss : 3.3862\n",
      "step : 36000, train loss : 3.4031, val loss : 3.3850\n",
      "step : 36300, train loss : 3.3916, val loss : 3.3749\n",
      "step : 36600, train loss : 3.3988, val loss : 3.3888\n",
      "step : 36900, train loss : 3.3811, val loss : 3.3718\n",
      "step : 37200, train loss : 3.3917, val loss : 3.3947\n",
      "step : 37500, train loss : 3.3892, val loss : 3.3698\n",
      "step : 37800, train loss : 3.3827, val loss : 3.4049\n",
      "step : 38100, train loss : 3.4033, val loss : 3.4108\n",
      "step : 38400, train loss : 3.3958, val loss : 3.3831\n",
      "step : 38700, train loss : 3.3650, val loss : 3.3809\n",
      "step : 39000, train loss : 3.3857, val loss : 3.3993\n",
      "step : 39300, train loss : 3.3829, val loss : 3.3838\n",
      "step : 39600, train loss : 3.3786, val loss : 3.4042\n",
      "step : 39900, train loss : 3.3923, val loss : 3.3971\n",
      "step : 40200, train loss : 3.3614, val loss : 3.3912\n",
      "step : 40500, train loss : 3.3767, val loss : 3.3927\n",
      "step : 40800, train loss : 3.3785, val loss : 3.3798\n",
      "step : 41100, train loss : 3.3652, val loss : 3.3877\n",
      "step : 41400, train loss : 3.4042, val loss : 3.3680\n",
      "step : 41700, train loss : 3.4056, val loss : 3.3802\n",
      "step : 42000, train loss : 3.3603, val loss : 3.3650\n",
      "step : 42300, train loss : 3.3600, val loss : 3.3560\n",
      "step : 42600, train loss : 3.3608, val loss : 3.3875\n",
      "step : 42900, train loss : 3.3878, val loss : 3.3733\n",
      "step : 43200, train loss : 3.3754, val loss : 3.3941\n",
      "step : 43500, train loss : 3.3828, val loss : 3.3977\n",
      "step : 43800, train loss : 3.3799, val loss : 3.3823\n",
      "step : 44100, train loss : 3.3957, val loss : 3.3838\n",
      "step : 44400, train loss : 3.3919, val loss : 3.3868\n",
      "step : 44700, train loss : 3.3653, val loss : 3.3753\n",
      "step : 45000, train loss : 3.3654, val loss : 3.3772\n",
      "step : 45300, train loss : 3.3838, val loss : 3.3805\n",
      "step : 45600, train loss : 3.3956, val loss : 3.3709\n",
      "step : 45900, train loss : 3.3576, val loss : 3.3642\n",
      "step : 46200, train loss : 3.4100, val loss : 3.4036\n",
      "step : 46500, train loss : 3.3947, val loss : 3.3713\n",
      "step : 46800, train loss : 3.3982, val loss : 3.3908\n",
      "step : 47100, train loss : 3.4309, val loss : 3.4181\n",
      "step : 47400, train loss : 3.3817, val loss : 3.3848\n",
      "step : 47700, train loss : 3.3854, val loss : 3.3709\n",
      "step : 48000, train loss : 3.3766, val loss : 3.3668\n",
      "step : 48300, train loss : 3.3585, val loss : 3.3508\n",
      "step : 48600, train loss : 3.3578, val loss : 3.3683\n",
      "step : 48900, train loss : 3.3611, val loss : 3.3764\n",
      "step : 49200, train loss : 3.3733, val loss : 3.3663\n",
      "step : 49500, train loss : 3.3801, val loss : 3.3563\n",
      "step : 49800, train loss : 3.3895, val loss : 3.3582\n",
      "-----------------------------------------------\n",
      " 지난달 부지난해 X5주 기업재트복센터와 널젤민 환자가 줄었다. 이사품 같 만마항공해부지받고 있다는 우리를 위해 감염작 및손우우가 1.1kg UF 영창에리는 팬터톡 검토째는 건 해s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iteration = 50000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iteration = 200\n",
    "n_embed = 32\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
    "        keys = self.key(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        values = self.value(inputs)\n",
    "        output = weights @ values\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def batch_function(mode):\n",
    "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
    "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
    "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_loss_metrics():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for mode in [\"train\", \"eval\"]:\n",
    "        losses = torch.zeros(eval_iteration)\n",
    "        for k in range(eval_iteration):\n",
    "            inputs, targets = batch_function(mode)\n",
    "            logits, loss = model(inputs, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[mode] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "#####\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.layer(input_tensor)\n",
    "#####\n",
    "\n",
    "class semiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_length, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.attention_head = MultiHeadAttention(4, n_embed//4)\n",
    "        self.feed_forward = FeedForward(n_embed)\n",
    "        # Block이 들어갈 위치\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        batch, sequence = inputs.shape\n",
    "\n",
    "        token_embed = self.token_embedding_table(inputs)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device))\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.attention_head(x)\n",
    "        x = self.feed_forward(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, sequence, embed_size = logits.shape\n",
    "            logits = logits.view(batch * sequence, embed_size)\n",
    "            targets = targets.view(batch * sequence)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "            inputs_cond = inputs[:, -block_size:]\n",
    "\n",
    "            logits, loss = self(inputs_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
    "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "model = semiGPT(ko_vocab_size).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for step in range(max_iteration):\n",
    "    if step % eval_interval == 0 :\n",
    "        losses = compute_loss_metrics()\n",
    "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
    "\n",
    "    example_x, example_y = batch_function(\"train\")\n",
    "    logits, loss = model(example_x, example_y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocks 만들기\n",
    "\n",
    "GPT와 같은 복잡한 신경망 모델에서 블록(Block)은 모델의 설계와 구현에 중요한 구조적 단위이다.\n",
    "\n",
    "블록 구조는 모델 내 다양한 계층과 구성 요소를 하나로 묶어 모듈화, 재사용성, 확장성을 크게 향샹시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 클래스의 코드\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
    "        self.feed_forward = FeedForward(n_embed)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
    "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
    "        return input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, train loss : 8.1663, val loss : 8.1647\n",
      "step : 300, train loss : 4.1377, val loss : 4.1575\n",
      "step : 600, train loss : 3.8563, val loss : 3.8552\n",
      "step : 900, train loss : 3.7203, val loss : 3.7374\n",
      "step : 1200, train loss : 3.6500, val loss : 3.6534\n",
      "step : 1500, train loss : 3.5745, val loss : 3.5688\n",
      "step : 1800, train loss : 3.5277, val loss : 3.5341\n",
      "step : 2100, train loss : 3.5020, val loss : 3.4801\n",
      "step : 2400, train loss : 3.4688, val loss : 3.4600\n",
      "step : 2700, train loss : 3.4423, val loss : 3.4285\n",
      "step : 3000, train loss : 3.4408, val loss : 3.4653\n",
      "step : 3300, train loss : 3.4356, val loss : 3.4213\n",
      "step : 3600, train loss : 3.4103, val loss : 3.3991\n",
      "step : 3900, train loss : 3.3984, val loss : 3.3733\n",
      "step : 4200, train loss : 3.3921, val loss : 3.3700\n",
      "step : 4500, train loss : 3.3866, val loss : 3.3745\n",
      "step : 4800, train loss : 3.3862, val loss : 3.3390\n",
      "step : 5100, train loss : 3.3544, val loss : 3.3493\n",
      "step : 5400, train loss : 3.3564, val loss : 3.3382\n",
      "step : 5700, train loss : 3.3349, val loss : 3.3400\n",
      "step : 6000, train loss : 3.3299, val loss : 3.3324\n",
      "step : 6300, train loss : 3.3338, val loss : 3.3306\n",
      "step : 6600, train loss : 3.3192, val loss : 3.3139\n",
      "step : 6900, train loss : 3.3124, val loss : 3.3136\n",
      "step : 7200, train loss : 3.3090, val loss : 3.3085\n",
      "step : 7500, train loss : 3.3075, val loss : 3.3241\n",
      "step : 7800, train loss : 3.3098, val loss : 3.3093\n",
      "step : 8100, train loss : 3.2966, val loss : 3.2947\n",
      "step : 8400, train loss : 3.2972, val loss : 3.3016\n",
      "step : 8700, train loss : 3.2922, val loss : 3.2824\n",
      "step : 9000, train loss : 3.2838, val loss : 3.2832\n",
      "step : 9300, train loss : 3.3146, val loss : 3.2848\n",
      "step : 9600, train loss : 3.2927, val loss : 3.2850\n",
      "step : 9900, train loss : 3.2859, val loss : 3.2814\n",
      "step : 10200, train loss : 3.2719, val loss : 3.2716\n",
      "step : 10500, train loss : 3.2726, val loss : 3.2800\n",
      "step : 10800, train loss : 3.2766, val loss : 3.2792\n",
      "step : 11100, train loss : 3.2638, val loss : 3.2477\n",
      "step : 11400, train loss : 3.2721, val loss : 3.2693\n",
      "step : 11700, train loss : 3.2989, val loss : 3.2695\n",
      "step : 12000, train loss : 3.2923, val loss : 3.2723\n",
      "step : 12300, train loss : 3.2660, val loss : 3.2637\n",
      "step : 12600, train loss : 3.2396, val loss : 3.2498\n",
      "step : 12900, train loss : 3.2963, val loss : 3.2750\n",
      "step : 13200, train loss : 3.2729, val loss : 3.2189\n",
      "step : 13500, train loss : 3.2569, val loss : 3.2468\n",
      "step : 13800, train loss : 3.2864, val loss : 3.2598\n",
      "step : 14100, train loss : 3.2589, val loss : 3.2661\n",
      "step : 14400, train loss : 3.2810, val loss : 3.2618\n",
      "step : 14700, train loss : 3.2533, val loss : 3.2674\n",
      "step : 15000, train loss : 3.2434, val loss : 3.2667\n",
      "step : 15300, train loss : 3.2466, val loss : 3.2688\n",
      "step : 15600, train loss : 3.2647, val loss : 3.2530\n",
      "step : 15900, train loss : 3.2380, val loss : 3.2486\n",
      "step : 16200, train loss : 3.2478, val loss : 3.2425\n",
      "step : 16500, train loss : 3.2451, val loss : 3.2422\n",
      "step : 16800, train loss : 3.2523, val loss : 3.2370\n",
      "step : 17100, train loss : 3.2465, val loss : 3.2327\n",
      "step : 17400, train loss : 3.2697, val loss : 3.2555\n",
      "step : 17700, train loss : 3.2661, val loss : 3.2587\n",
      "step : 18000, train loss : 3.2717, val loss : 3.2665\n",
      "step : 18300, train loss : 3.2527, val loss : 3.2463\n",
      "step : 18600, train loss : 3.2343, val loss : 3.2463\n",
      "step : 18900, train loss : 3.2427, val loss : 3.2490\n",
      "step : 19200, train loss : 3.2604, val loss : 3.2447\n",
      "step : 19500, train loss : 3.2291, val loss : 3.2102\n",
      "step : 19800, train loss : 3.2449, val loss : 3.2395\n",
      "step : 20100, train loss : 3.2292, val loss : 3.2319\n",
      "step : 20400, train loss : 3.2558, val loss : 3.2359\n",
      "step : 20700, train loss : 3.2359, val loss : 3.2273\n",
      "step : 21000, train loss : 3.2188, val loss : 3.2507\n",
      "step : 21300, train loss : 3.2393, val loss : 3.2287\n",
      "step : 21600, train loss : 3.2394, val loss : 3.2373\n",
      "step : 21900, train loss : 3.2580, val loss : 3.2242\n",
      "step : 22200, train loss : 3.2471, val loss : 3.2558\n",
      "step : 22500, train loss : 3.2253, val loss : 3.2366\n",
      "step : 22800, train loss : 3.2381, val loss : 3.2475\n",
      "step : 23100, train loss : 3.2224, val loss : 3.2376\n",
      "step : 23400, train loss : 3.2295, val loss : 3.2139\n",
      "step : 23700, train loss : 3.2504, val loss : 3.2155\n",
      "step : 24000, train loss : 3.2359, val loss : 3.2119\n",
      "step : 24300, train loss : 3.2422, val loss : 3.2329\n",
      "step : 24600, train loss : 3.2237, val loss : 3.2462\n",
      "step : 24900, train loss : 3.2377, val loss : 3.2492\n",
      "step : 25200, train loss : 3.2409, val loss : 3.2308\n",
      "step : 25500, train loss : 3.2289, val loss : 3.2458\n",
      "step : 25800, train loss : 3.2651, val loss : 3.2545\n",
      "step : 26100, train loss : 3.2068, val loss : 3.2078\n",
      "step : 26400, train loss : 3.2361, val loss : 3.2099\n",
      "step : 26700, train loss : 3.2103, val loss : 3.2429\n",
      "step : 27000, train loss : 3.2143, val loss : 3.2202\n",
      "step : 27300, train loss : 3.2181, val loss : 3.2259\n",
      "step : 27600, train loss : 3.2334, val loss : 3.2429\n",
      "step : 27900, train loss : 3.2207, val loss : 3.2275\n",
      "step : 28200, train loss : 3.2258, val loss : 3.2102\n",
      "step : 28500, train loss : 3.2325, val loss : 3.2159\n",
      "step : 28800, train loss : 3.2150, val loss : 3.2285\n",
      "step : 29100, train loss : 3.2053, val loss : 3.2170\n",
      "step : 29400, train loss : 3.2188, val loss : 3.2212\n",
      "step : 29700, train loss : 3.2262, val loss : 3.2222\n",
      "step : 30000, train loss : 3.2455, val loss : 3.2392\n",
      "step : 30300, train loss : 3.2447, val loss : 3.2143\n",
      "step : 30600, train loss : 3.2156, val loss : 3.2177\n",
      "step : 30900, train loss : 3.2061, val loss : 3.2148\n",
      "step : 31200, train loss : 3.2277, val loss : 3.2320\n",
      "step : 31500, train loss : 3.2150, val loss : 3.2117\n",
      "step : 31800, train loss : 3.2351, val loss : 3.2301\n",
      "step : 32100, train loss : 3.2312, val loss : 3.2183\n",
      "step : 32400, train loss : 3.2346, val loss : 3.2264\n",
      "step : 32700, train loss : 3.2300, val loss : 3.2261\n",
      "step : 33000, train loss : 3.2322, val loss : 3.2267\n",
      "step : 33300, train loss : 3.2066, val loss : 3.2176\n",
      "step : 33600, train loss : 3.2222, val loss : 3.2097\n",
      "step : 33900, train loss : 3.2283, val loss : 3.1954\n",
      "step : 34200, train loss : 3.2338, val loss : 3.2390\n",
      "step : 34500, train loss : 3.2102, val loss : 3.2111\n",
      "step : 34800, train loss : 3.2078, val loss : 3.2067\n",
      "step : 35100, train loss : 3.2211, val loss : 3.2207\n",
      "step : 35400, train loss : 3.2015, val loss : 3.2001\n",
      "step : 35700, train loss : 3.1999, val loss : 3.2006\n",
      "step : 36000, train loss : 3.2184, val loss : 3.2096\n",
      "step : 36300, train loss : 3.2133, val loss : 3.2248\n",
      "step : 36600, train loss : 3.2067, val loss : 3.2113\n",
      "step : 36900, train loss : 3.2166, val loss : 3.2282\n",
      "step : 37200, train loss : 3.2254, val loss : 3.1923\n",
      "step : 37500, train loss : 3.2031, val loss : 3.2048\n",
      "step : 37800, train loss : 3.2110, val loss : 3.1870\n",
      "step : 38100, train loss : 3.2079, val loss : 3.2167\n",
      "step : 38400, train loss : 3.2158, val loss : 3.1784\n",
      "step : 38700, train loss : 3.2104, val loss : 3.2317\n",
      "step : 39000, train loss : 3.2063, val loss : 3.2086\n",
      "step : 39300, train loss : 3.2155, val loss : 3.2023\n",
      "step : 39600, train loss : 3.2120, val loss : 3.2044\n",
      "step : 39900, train loss : 3.2008, val loss : 3.2169\n",
      "step : 40200, train loss : 3.2096, val loss : 3.1735\n",
      "step : 40500, train loss : 3.2203, val loss : 3.2016\n",
      "step : 40800, train loss : 3.2189, val loss : 3.2463\n",
      "step : 41100, train loss : 3.1929, val loss : 3.2164\n",
      "step : 41400, train loss : 3.2036, val loss : 3.2131\n",
      "step : 41700, train loss : 3.2173, val loss : 3.2082\n",
      "step : 42000, train loss : 3.1766, val loss : 3.1825\n",
      "step : 42300, train loss : 3.1996, val loss : 3.2021\n",
      "step : 42600, train loss : 3.2004, val loss : 3.1982\n",
      "step : 42900, train loss : 3.2033, val loss : 3.2176\n",
      "step : 43200, train loss : 3.1955, val loss : 3.1963\n",
      "step : 43500, train loss : 3.1999, val loss : 3.2069\n",
      "step : 43800, train loss : 3.1967, val loss : 3.1895\n",
      "step : 44100, train loss : 3.2193, val loss : 3.1757\n",
      "step : 44400, train loss : 3.2050, val loss : 3.1903\n",
      "step : 44700, train loss : 3.2074, val loss : 3.2197\n",
      "step : 45000, train loss : 3.2010, val loss : 3.2096\n",
      "step : 45300, train loss : 3.2154, val loss : 3.1839\n",
      "step : 45600, train loss : 3.2076, val loss : 3.2103\n",
      "step : 45900, train loss : 3.2229, val loss : 3.2036\n",
      "step : 46200, train loss : 3.2372, val loss : 3.2153\n",
      "step : 46500, train loss : 3.2128, val loss : 3.1940\n",
      "step : 46800, train loss : 3.2239, val loss : 3.2046\n",
      "step : 47100, train loss : 3.2098, val loss : 3.1923\n",
      "step : 47400, train loss : 3.2002, val loss : 3.1936\n",
      "step : 47700, train loss : 3.1732, val loss : 3.1910\n",
      "step : 48000, train loss : 3.2225, val loss : 3.2190\n",
      "step : 48300, train loss : 3.1944, val loss : 3.1861\n",
      "step : 48600, train loss : 3.1986, val loss : 3.1973\n",
      "step : 48900, train loss : 3.2207, val loss : 3.2078\n",
      "step : 49200, train loss : 3.2120, val loss : 3.1968\n",
      "step : 49500, train loss : 3.2128, val loss : 3.1834\n",
      "step : 49800, train loss : 3.2142, val loss : 3.1917\n",
      "-----------------------------------------------\n",
      " 나옵치 비 제도 총 행산을 놀f은 k낄 것서 이라며 로 이고 유·옐는 한국종’과 동일부터 소비자 토르관리지역전은 단순균환경우도가 좋고 있다고 보험은 걸백선김 있다 고 말했다. 전환\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iteration = 50000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iteration = 200\n",
    "n_embed = 32\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.1\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
    "        keys = self.key(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        values = self.value(inputs)\n",
    "        output = weights @ values\n",
    "        return output\n",
    "\n",
    "\n",
    "def batch_function(mode):\n",
    "    dataset = train_dataset if mode == \"train\" else test_dataset\n",
    "    idx = torch.randint(len(dataset) - block_size, (batch_size,))\n",
    "    x = torch.stack([dataset[index:index+block_size] for index in idx])\n",
    "    y = torch.stack([dataset[index+1:index+block_size+1] for index in idx])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_loss_metrics():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for mode in [\"train\", \"eval\"]:\n",
    "        losses = torch.zeros(eval_iteration)\n",
    "        for k in range(eval_iteration):\n",
    "            inputs, targets = batch_function(mode)\n",
    "            logits, loss = model(inputs, targets)\n",
    "            losses[k] = loss.item()\n",
    "        out[mode] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.layer(input_tensor)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
    "        self.feed_forward = FeedForward(n_embed)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
    "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "class semiGPT(nn.Module):\n",
    "    def __init__(self, vocab_length):\n",
    "        super().__init__()\n",
    "        self.embedding_token_table = nn.Embedding(vocab_length, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed, 4) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_length)\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        batch, sequence = inputs.shape\n",
    "\n",
    "        token_embed = self.embedding_token_table(inputs) # (B, T, C)\n",
    "        pos_embed = self.position_embedding_table(torch.arange(sequence, device=device)) # (T, C)\n",
    "        x = token_embed + pos_embed\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch, sequence, embed_size = logits.shape\n",
    "            logits = logits.view(batch * sequence, embed_size)\n",
    "            targets = targets.view(batch * sequence)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            inputs_cond = inputs[:, -block_size:]\n",
    "\n",
    "            logits, loss = self(inputs_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_inputs = torch.multinomial(probs, num_samples=1)\n",
    "            inputs = torch.cat((inputs, next_inputs), dim=1)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "model = semiGPT(ko_vocab_size).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for step in range(max_iteration):\n",
    "    if step % eval_interval == 0 :\n",
    "        losses = compute_loss_metrics()\n",
    "        print(f'step : {step}, train loss : {losses[\"train\"]:.4f}, val loss : {losses[\"eval\"]:.4f}')\n",
    "\n",
    "    example_x, example_y = batch_function(\"train\")\n",
    "    logits, loss = model(example_x, example_y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "inputs = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(\"-----------------------------------------------\")\n",
    "print(token_decode(model.generate(inputs, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Generated Text:  의사를 사무가 후보내다. 놀지 중국 사위주는 일대를 수표로 지금 10대 3주년 9의 연 결제를 거나3눴다. 나전기엔 카카오 것으로 인상멧은 “이부 금융가 보인다. 3만 MAMZ 서션 \n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "input_word = \"의사\"\n",
    "input_ids = [character_to_ids[char] for char in input_word if char in character_to_ids]\n",
    "\n",
    "# 입력 텐서 생성\n",
    "inputs = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "\n",
    "# 모델을 사용하여 텍스트 생성\n",
    "outputs = model.generate(inputs, 100)\n",
    "\n",
    "# 생성된 결과 디코딩\n",
    "generated_text = \"\".join([ids_to_character.get(i, '') for i in outputs[0].tolist()])\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Generated Text: \", generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토크나이저\n",
    "\n",
    "효과적인 토크나이저는 텍스트의 의미를 잘 보존하면서도 데이터를 효율적으로 처리할 수 있게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Vocabulary size: 10000\n",
      "Original: 안녕하세요\n",
      "Encoded: [1912, 1172, 2549, 9020]\n",
      "Decoded: 안 녕 하 세요\n",
      "Tokens: ['안', '녕', '하', '세요']\n",
      "\n",
      "Original: 자연어 처리는 매우 흥미로운 분야입니다\n",
      "Encoded: [4466, 1945, 2242, 2982, 4637, 2648, 1580, 3063, 2931, 2949]\n",
      "Decoded: 자연 어 처 리는 매우 흥 미 로운 분야 입니다\n",
      "Tokens: ['자연', '어', '처', '리는', '매우', '흥', '미', '로운', '분야', '입니다']\n",
      "\n",
      "Original: 인공지능과 기계학습의 발전이 놀랍습니다\n",
      "Encoded: [3765, 982, 5093, 5017, 2063, 3100, 2065, 1177, 1394, 2727]\n",
      "Decoded: 인공지능 과 기계 학습 의 발전 이 놀 랍 습니다\n",
      "Tokens: ['인공지능', '과', '기계', '학습', '의', '발전', '이', '놀', '랍', '습니다']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 만들기\n",
    "import os\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "# 저장할 디렉토리 경로 설정\n",
    "SAVE_DIR = \"content/\"\n",
    "\n",
    "# 디렉토리가 없으면 생성\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 원하는 어휘 크기 설정\n",
    "VOCAB_SIZE = 10000\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# 트레이너 준비 (vocab_size 지정)\n",
    "trainer = BpeTrainer(\n",
    "    special_tokens=[\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"],\n",
    "    vocab_size=VOCAB_SIZE\n",
    ")\n",
    "\n",
    "# 토크나이저 학습\n",
    "def batch_iterator(batch_size=1000):\n",
    "    for i in range(0, len(dataset[\"train\"]), batch_size):\n",
    "        yield dataset[\"train\"][i : i + batch_size][\"document\"]\n",
    "\n",
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
    "\n",
    "# 토크나이저를 JSON 파일로 저장\n",
    "tokenizer_path = os.path.join(SAVE_DIR, \"tokenizer.json\")\n",
    "tokenizer.save(tokenizer_path)\n",
    "\n",
    "# 토크나이저를 Hugging Face 형식으로 변환\n",
    "huggingface_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    unk_token=\"<unk>\",\n",
    "    bos_token=\"<s>\",\n",
    "    eos_token=\"</s>\",\n",
    "    pad_token=\"<pad>\"\n",
    ")\n",
    "\n",
    "# Hugging Face 형식의 토크나이저 저장\n",
    "huggingface_path = os.path.join(SAVE_DIR, \"huggingface_tokenizer\")\n",
    "huggingface_tokenizer.save_pretrained(huggingface_path)\n",
    "\n",
    "# Hugging Face 형식의 토크나이저 로드\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_path)\n",
    "\n",
    "# 어휘 크기 확인\n",
    "print(f\"Vocabulary size: {len(tokenizer.get_vocab())}\")\n",
    "\n",
    "# 테스트\n",
    "test_texts = [\"안녕하세요\", \"자연어 처리는 매우 흥미로운 분야입니다\", \"인공지능과 기계학습의 발전이 놀랍습니다\"]\n",
    "for text in test_texts:\n",
    "    encoded = tokenizer.encode(text)\n",
    "    print(f\"Original: {text}\")\n",
    "    print(f\"Encoded: {encoded}\")\n",
    "    print(f\"Decoded: {tokenizer.decode(encoded)}\")\n",
    "    print(f\"Tokens: {tokenizer.convert_ids_to_tokens(encoded)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='content/huggingface_tokenizer', vocab_size=10000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최종 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 파라미터 수: 0.70M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, train loss : 9.3706, val loss : 9.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:02<17:50, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 10, train loss : 3.6829, val loss : 5.8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [04:04<15:53, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 20, train loss : 3.3648, val loss : 6.0488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [06:02<13:09, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 30, train loss : 3.2323, val loss : 6.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [07:58<11:16, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 40, train loss : 3.1974, val loss : 6.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [09:53<09:22, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 50, train loss : 3.1459, val loss : 6.2845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [11:49<07:30, 11.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 60, train loss : 3.0931, val loss : 6.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [13:46<05:51, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 70, train loss : 3.0674, val loss : 6.4840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [15:45<03:47, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 80, train loss : 3.0808, val loss : 6.4226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [17:47<01:59, 11.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 90, train loss : 3.0595, val loss : 6.4553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:50<00:00, 11.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: 의사 상품 게임 은 재건축 · 공원 · 3개월 만에 4 개 지정 세 노조 제안 으로 존 분석 총 개선 둔화 하면서 패션 사람들이 엄 신용 위원회 기간 3개 도 진단 사 치 업 권 영수 부회장이 글로벌 세계 가상인간 상반기 제출한 청 법인 날 식 … 이다 지급 참여 예고 스에서 6 10일 2022 한덕수 총리 임 병 내 국방 럴 4차 산업 산업 연구소 에서 설립 허준이 홍 배 총 고등과학원 AS 농 민 선 정부 첫 뒤 시즌 와 쿨 지수 공개 입법 보니 개선 … 사법 세를 된다 마감 ... 6개 시 성구 나 점 프로세\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "max_iteration = 100\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-2\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "eval_iteration = 10\n",
    "n_embed = 32\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, sequence_length, embedding_dim = inputs.shape\n",
    "        keys = self.key(inputs)\n",
    "        queries = self.query(inputs)\n",
    "        weights = queries @ keys.transpose(-2, -1) * (embedding_dim ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:sequence_length, :sequence_length] == 0, float(\"-inf\"))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        values = self.value(inputs)\n",
    "        output = weights @ values\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        return torch.cat([head(inputs) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        return self.layer(input_tensor)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_heads):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.attention = MultiHeadAttention(n_heads, head_size)\n",
    "        self.feed_forward = FeedForward(n_embed)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embed)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embed)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        input_tensor = input_tensor + self.attention(self.layer_norm1(input_tensor))\n",
    "        input_tensor = input_tensor + self.feed_forward(self.layer_norm2(input_tensor))\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "# 데이터셋 전처리\n",
    "def preprocess_dataset(dataset, tokenizer):\n",
    "    encoded_data = [tokenizer.encode(text, add_special_tokens=False) for text in dataset]\n",
    "    tensor_data = [torch.tensor(seq, dtype=torch.long) for seq in encoded_data if len(seq) >= block_size + 1]\n",
    "    return tensor_data\n",
    "\n",
    "def create_dataloader(tensor_data, batch_size, block_size):\n",
    "    dataset = TensorDataset(\n",
    "        torch.stack([seq[:block_size] for seq in tensor_data]).to(device),\n",
    "        torch.stack([seq[1:block_size+1] for seq in tensor_data]).to(device)\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class semiGPT(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embed)\n",
    "        self.blocks = nn.ModuleList([Block(n_embed, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device))\n",
    "        x = token_emb + pos_emb\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "# 데이터 전처리\n",
    "n = int(0.9 * len(dataset[\"train\"][\"document\"]))\n",
    "train_data = preprocess_dataset(dataset[\"train\"][\"document\"][:n], tokenizer)\n",
    "test_data = preprocess_dataset(dataset[\"train\"][\"document\"][n:], tokenizer)\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = create_dataloader(train_data, batch_size, block_size)\n",
    "test_loader = create_dataloader(test_data, batch_size, block_size)\n",
    "\n",
    "# 모델 초기화\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "model = semiGPT(vocab_size).to(device)\n",
    "print(f\"모델의 파라미터 수: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 평가 함수\n",
    "@torch.no_grad()\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, loss = model(x, y)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 학습 루프\n",
    "from tqdm.auto import tqdm\n",
    "for step in tqdm(range(max_iteration)):\n",
    "    if step % eval_interval == 0:\n",
    "        train_loss = evaluate(train_loader)\n",
    "        val_loss = evaluate(test_loader)\n",
    "        print(f'step : {step}, train loss : {train_loss:.4f}, val loss : {val_loss:.4f}')\n",
    "\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits, loss = model(x, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 텍스트 생성\n",
    "context = \"의사\"\n",
    "context_encoded = tokenizer.encode(context, return_tensors='pt').to(device)\n",
    "generated_ids = model.generate(context_encoded, max_new_tokens=100)[0]\n",
    "generated_text = tokenizer.decode(generated_ids)\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
