{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haiqv/conda/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists: ./llama-3.2-korean-3b-hf-20-epoch/checkpoint-4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:26<00:00,  8.80s/it]\n",
      "Generating train split: 2116 examples [00:00, 184135.51 examples/s]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:\n",
      "와사비와 겨자의 차이점이 무엇인가요?\n",
      "정답:\n",
      "와사비는 고추냉이를 갈아서 사용하는 반면, 겨자는 겨자의 씨앗을 갈아서 만듭니다. 와사비는 찬물에 개어서 신랄한 향을 내며, 겨자는 뜨거운 물에 발효시켜 강한 매운 맛을 냅니다. 따라서, 와사비는 비린내를 없애고 가벼운 맛을 내는 간장소스와 같은 요리에 사용되며, 겨자는 냉채나 무침, 돈까스 소스 등 강한 맛을 내는 요리에 사용됩니다. 또한, 와사비는 향이 강한 반면 겨자는 맛이 강하다고 할 수 있습니다.\n",
      "생성:\n",
      "1. 와사비는 일본에서 자란 식물으로, 겨자와 비슷한 모양을 가지고 있습니다. 그러나 사용 용도가 다르며, 주로 일본 요리에서 사용됩니다. \n",
      "2. 겨자는 인도에서 자라는 식물로, 매우 매운 맛을 가지고 있습니다. 중국 요리에서 사용되는 경우도 많습니다. \n",
      "3. 사프란은 프랑스에서 자라는 식물로,과일과 채소를 잘라내어 염산에 담가 매운 맛을 내는 음식입니다. 주로 프랑스 요리에서 사용됩니다. \n",
      "4. 고추는 중국에서 자라는 식물로, 매운 맛이 강합니다. 한국, 일본, 미국, 중국 등에서 다양한 요리로 즐겨먹고 있습니다. \n",
      "\n",
      "위의 식물들은 모두 매운 맛을 가지고 있지만, 사용 용도와 조리 방법에 차이가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "from random import randint\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "# \"/home/haiqv/llm_finetuning_book/03_5_Llama/llama-3.2-korean-3b-hf-20-epoch/checkpoint-4740\"\n",
    "# model_name = \"/home/haiqv/llm_finetuning_book/03_5_Llama/llama-3.2-korean-3b-hf-20-epoch/checkpoint-4740\"\n",
    "model_name = \"./llama-3.2-korean-3b-hf-20-epoch/checkpoint-4740\"\n",
    "if not os.path.exists(model_name):\n",
    "    print(f\"Path does not exist: {model_name}\")\n",
    "else:\n",
    "    print(f\"Path exists: {model_name}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "test_dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=os.path.join(\"\", \"./test_dataset.json\"),\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "test_dataset = load_dataset(\"json\", \n",
    "                            split=\"train\",\n",
    "                            data_files=\"test_dataset.json\")\n",
    "\n",
    "random_index = randint(0, len(test_dataset))\n",
    "messages = test_dataset[random_index][\"messages\"][:2]\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(messages,\n",
    "                                          add_generation_prompt=True,\n",
    "                                          return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(f\"질문:\\n{test_dataset[random_index]['messages'][1]['content']}\")\n",
    "print(f\"정답:\\n{test_dataset[random_index]['messages'][2]['content']}\")\n",
    "print(f\"생성:\\n{tokenizer.decode(response,skip_special_tokens=True)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
